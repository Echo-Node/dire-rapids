Metadata-Version: 2.1
Name: dire-rapids
Version: 0.1.0
Summary: PyTorch and RAPIDS (cuVS/cuML) accelerated dimensionality reduction
Home-page: https://github.com/sashakolpakov/dire-rapids
Author: Alexander Kolpakov (UATX), Igor Rivin (Temple University)
Author-email: akolpakov@uaustin.org, rivin@temple.edu
Maintainer: Alexander Kolpakov
Maintainer-email: akolpakov@uaustin.org
License: MIT
Project-URL: Bug Reports, https://github.com/sashakolpakov/dire-rapids/issues
Project-URL: Source, https://github.com/sashakolpakov/dire-rapids
Project-URL: Documentation, https://github.com/sashakolpakov/dire-rapids#readme
Keywords: dimensionality-reduction machine-learning gpu cuda rapids pytorch visualization embedding umap tsne
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Scientific/Engineering :: Visualization
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Operating System :: OS Independent
Classifier: Environment :: GPU :: NVIDIA CUDA
Requires-Python: >=3.8,<3.12
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.21.0
Requires-Dist: torch>=2.0.0
Requires-Dist: pykeops>=2.1.0
Requires-Dist: loguru>=0.6.0
Requires-Dist: tqdm>=4.62.0
Requires-Dist: scipy>=1.7.0
Requires-Dist: scikit-learn>=1.0.0
Requires-Dist: pandas>=1.3.0
Requires-Dist: plotly>=5.0.0
Provides-Extra: cuda
Requires-Dist: cupy-cuda11x>=10.0.0; extra == "cuda"
Provides-Extra: rapids
Requires-Dist: cuml-cu11>=23.0.0; extra == "rapids"
Requires-Dist: cuvs-cu11>=23.0.0; extra == "rapids"
Requires-Dist: cudf-cu11>=23.0.0; extra == "rapids"
Requires-Dist: cupy-cuda11x>=10.0.0; extra == "rapids"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: pytest-xdist>=3.0.0; extra == "dev"
Requires-Dist: pytest-timeout>=2.1.0; extra == "dev"
Requires-Dist: matplotlib>=3.5.0; extra == "dev"
Requires-Dist: seaborn>=0.11.0; extra == "dev"
Requires-Dist: ipython>=8.0.0; extra == "dev"
Requires-Dist: jupyter>=1.0.0; extra == "dev"
Requires-Dist: notebook>=6.4.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: isort>=5.10.0; extra == "dev"
Requires-Dist: flake8>=4.0.0; extra == "dev"
Requires-Dist: pylint>=2.15.0; extra == "dev"
Requires-Dist: mypy>=0.950; extra == "dev"
Requires-Dist: memory_profiler>=0.60.0; extra == "dev"
Requires-Dist: line_profiler>=3.5.0; extra == "dev"
Provides-Extra: test
Requires-Dist: pytest>=7.0.0; extra == "test"
Requires-Dist: pytest-cov>=4.0.0; extra == "test"
Requires-Dist: pytest-xdist>=3.0.0; extra == "test"
Requires-Dist: pytest-timeout>=2.1.0; extra == "test"
Provides-Extra: docs
Requires-Dist: sphinx>=4.5.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.0.0; extra == "docs"
Requires-Dist: nbsphinx>=0.8.0; extra == "docs"
Requires-Dist: myst-parser>=0.17.0; extra == "docs"

# dire-rapids

PyTorch and RAPIDS accelerated dimensionality reduction

GPU-accelerated implementation of DiRe (Dimensionality Reduction) using PyTorch and optionally NVIDIA RAPIDS for massive-scale datasets.

## Installation

### From Repository

```bash
# Clone the repository
git clone https://github.com/sashakolpakov/dire-rapids.git
cd dire-rapids

# Basic installation (CPU + PyTorch)
pip install -e .

# With CUDA support
pip install -e .[cuda]

# For development (includes testing and dev tools)
pip install -e .[dev]
```

### With RAPIDS Support (Optional, GPU only)

```bash
# First install RAPIDS (requires CUDA 11.x or 12.x)
conda install -c rapidsai -c conda-forge -c nvidia rapids=24.10 python=3.11 cuda-version=11.8

# Then install dire-rapids with RAPIDS support
pip install -e .[rapids]
```

## Quick Start

```python
from dire_rapids import DiRePyTorch, DiRePyTorchMemoryEfficient
import numpy as np

# Generate sample data
X = np.random.randn(1000, 50).astype(np.float32)

# Standard PyTorch implementation
model = DiRePyTorch(n_components=2, n_neighbors=15)
X_embedded = model.fit_transform(X)

# Memory-efficient version (recommended for large datasets)
# Uses FP16, point-by-point forces, and aggressive memory management
model_efficient = DiRePyTorchMemoryEfficient(
    n_components=2, 
    n_neighbors=15,
    use_fp16=True,  # Use half precision for memory savings
    memory_fraction=0.15  # Conservative GPU memory usage
)
X_embedded_efficient = model_efficient.fit_transform(X)

print(X_embedded.shape)  # (1000, 2)
```

### Available Backends

- **DiRePyTorch**: Standard PyTorch implementation with adaptive chunking
- **DiRePyTorchMemoryEfficient**: Memory-optimized version with:
  - FP16 support for 2x memory savings
  - Point-by-point force computation
  - More aggressive memory management
  - PyKeOps LazyTensors for efficient repulsion (when available)
- **DiReCuVS** (optional): RAPIDS cuVS backend for massive-scale datasets

## Testing

```bash
# Run basic CPU tests
pytest tests/test_cpu_basic.py -v

# Run all tests
pytest tests/ -v
```

## Requirements

- Python 3.8-3.11
- PyTorch 2.0+
- PyKeOps 2.1+
- NumPy, SciPy, scikit-learn
- (Optional) CUDA 11.x+ for GPU acceleration
- (Optional) RAPIDS 23.08+ for cuVS backend
